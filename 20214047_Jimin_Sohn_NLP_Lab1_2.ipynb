{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# NLP LAB Problem 2"
      ],
      "metadata": {
        "id": "J9KmVy9Jt42D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preparation"
      ],
      "metadata": {
        "id": "5O8ABSjzwHf1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Load input symbol sequence"
      ],
      "metadata": {
        "id": "-mHFm2KOwKmc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "sKO0On1qw0f6"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_data(data_dir, is_train):\n",
        "    data, labels = [], []\n",
        "    \n",
        "    if is_train:\n",
        "        file_name = os.path.join(data_dir, 'simple_seq.train.csv')\n",
        "        with open(os.path.join(file_name), 'rb') as f:\n",
        "            file = f.read().decode('utf-8').replace('\\r', '')\n",
        "            content = file.split('\\n')\n",
        "            for line in content:\n",
        "                line = line.strip(',')\n",
        "                line_list = line.split(',')\n",
        "                data.append(line_list[:-1])\n",
        "                labels.append(line_list[-1])\n",
        "        return data, labels\n",
        "    else:\n",
        "        file_name = os.path.join(data_dir, 'simple_seq.test.csv')\n",
        "        with open(os.path.join(file_name), 'rb') as f:\n",
        "            file = f.read().decode('utf-8').replace('\\r', '')\n",
        "            content = file.split('\\n')\n",
        "            for line in content:\n",
        "                line = line.strip(',')\n",
        "                line_list = line.split(',')\n",
        "                data.append(line_list)\n",
        "        return data"
      ],
      "metadata": {
        "id": "z2GYabcpwON2"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = './lab1-2_data'\n",
        "# Train Data\n",
        "train_x_list, train_y_list = read_data(data_dir, True) # train #: 900\n",
        "train_x_list, train_y_list = train_x_list[:-1], train_y_list[:-1]\n",
        "train_len = len(train_y_list)\n",
        "print(len(train_x_list), len(train_y_list))\n",
        "\n",
        "# Test Data\n",
        "test_x_list = read_data(data_dir, False) # test #: 100\n",
        "test_x_list = test_x_list[:-1]\n",
        "test_len = len(test_x_list)\n",
        "print(len(test_x_list))"
      ],
      "metadata": {
        "id": "BUPKUr-4wOF1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0be0a6e8-ebc9-4a91-d6a0-cb293115d774"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "900 900\n",
            "100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Replace the dictionary(generated at Lab1-problem 1) into trainable word embedding"
      ],
      "metadata": {
        "id": "Lcn86Py-30cE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# lookup table is a dictionary object containing the relationship between words and ids\n",
        "with open('./word_dict_1.pickle','rb') as f: # word_dict_1: 1076\n",
        "    word_dict_1 = pickle.load(f)\n",
        "\n",
        "print(word_dict_1)\n",
        "print(len(word_dict_1))\n",
        "len_symbol_sequence = len(word_dict_1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aK6n9g2W30Lv",
        "outputId": "bccc3596-6adc-4581-f355-ab0dd6a0734b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'unknown': 0, 'W2554': 1, 'W446': 2, 'W2486': 3, 'W155': 4, 'W930': 5, 'W4462': 6, 'W568': 7, 'W412': 8, 'W809': 9, 'W3852': 10, 'W4706': 11, 'W4665': 12, 'W3167': 13, 'W2832': 14, 'W2068': 15, 'W973': 16, 'W300': 17, 'W5376': 18, 'W801': 19, 'W1061': 20, 'W5118': 21, 'W66': 22, 'W5227': 23, 'W252': 24, 'W170': 25, 'W5381': 26, 'W4495': 27, 'W2232': 28, 'W2329': 29, 'W2055': 30, 'W5389': 31, 'W2929': 32, 'W2189': 33, 'W1365': 34, 'W408': 35, 'W216': 36, 'W1125': 37, 'W1926': 38, 'W3117': 39, 'W53': 40, 'W3968': 41, 'W4789': 42, 'W1586': 43, 'W3384': 44, 'W5330': 45, 'W223': 46, 'W3948': 47, 'W3169': 48, 'W2961': 49, 'W83': 50, 'W1368': 51, 'W5267': 52, 'W1832': 53, 'W5414': 54, 'W844': 55, 'W105': 56, 'W1343': 57, 'W217': 58, 'W3526': 59, 'W1242': 60, 'W3306': 61, 'W641': 62, 'W496': 63, 'W5115': 64, 'W528': 65, 'W3625': 66, 'W654': 67, 'W264': 68, 'W325': 69, 'W4682': 70, 'W1982': 71, 'W2567': 72, 'W2094': 73, 'W219': 74, 'W6': 75, 'W1450': 76, 'W1775': 77, 'W3690': 78, 'W2026': 79, 'W5415': 80, 'W1335': 81, 'W2955': 82, 'W5282': 83, 'W108': 84, 'W334': 85, 'W69': 86, 'W2678': 87, 'W3954': 88, 'W341': 89, 'W4513': 90, 'W2227': 91, 'W432': 92, 'W2575': 93, 'W401': 94, 'W2570': 95, 'W213': 96, 'W954': 97, 'W5277': 98, 'W506': 99, 'W2897': 100, 'W5242': 101, 'W2052': 102, 'W855': 103, 'W1127': 104, 'W4537': 105, 'W340': 106, 'W395': 107, 'W1174': 108, 'W1601': 109, 'W2599': 110, 'W225': 111, 'W5232': 112, 'W1210': 113, 'W2047': 114, 'W848': 115, 'W1658': 116, 'W1707': 117, 'W31': 118, 'W3265': 119, 'W3761': 120, 'W1020': 121, 'W310': 122, 'W17': 123, 'W220': 124, 'W2982': 125, 'W35': 126, 'W748': 127, 'W1058': 128, 'W4135': 129, 'W3263': 130, 'W2610': 131, 'W27': 132, 'W507': 133, 'W5329': 134, 'W626': 135, 'W2898': 136, 'W1375': 137, 'W1562': 138, 'W663': 139, 'W642': 140, 'W912': 141, 'W1038': 142, 'W5206': 143, 'W1270': 144, 'W2210': 145, 'W4756': 146, 'W4172': 147, 'W2463': 148, 'W2423': 149, 'W168': 150, 'W3530': 151, 'W659': 152, 'W1990': 153, 'W616': 154, 'W3692': 155, 'W516': 156, 'W141': 157, 'W3668': 158, 'W456': 159, 'W532': 160, 'W5120': 161, 'W933': 162, 'W1536': 163, 'W4391': 164, 'W873': 165, 'W259': 166, 'W344': 167, 'W357': 168, 'W1904': 169, 'W1769': 170, 'W131': 171, 'W398': 172, 'W3942': 173, 'W5218': 174, 'W909': 175, 'W5281': 176, 'W376': 177, 'W4283': 178, 'W2586': 179, 'W5371': 180, 'W32': 181, 'W3248': 182, 'W5083': 183, 'W64': 184, 'W5117': 185, 'W1280': 186, 'W4705': 187, 'W2200': 188, 'W3290': 189, 'W379': 190, 'W3714': 191, 'W19': 192, 'W67': 193, 'W1312': 194, 'W1074': 195, 'W2743': 196, 'W3188': 197, 'W374': 198, 'W475': 199, 'W2253': 200, 'W5385': 201, 'W5375': 202, 'W840': 203, 'W665': 204, 'W679': 205, 'W307': 206, 'W36': 207, 'W1515': 208, 'W1085': 209, 'W903': 210, 'W4981': 211, 'W94': 212, 'W90': 213, 'W480': 214, 'W982': 215, 'W3931': 216, 'W1253': 217, 'W548': 218, 'W348': 219, 'W2036': 220, 'W369': 221, 'W2348': 222, 'W566': 223, 'W3069': 224, 'W647': 225, 'W167': 226, 'W5293': 227, 'W1165': 228, 'W112': 229, 'W5044': 230, 'W3279': 231, 'W1692': 232, 'W117': 233, 'W3156': 234, 'W137': 235, 'W2757': 236, 'W1477': 237, 'W301': 238, 'W1395': 239, 'W1984': 240, 'W1606': 241, 'W3739': 242, 'W406': 243, 'W4078': 244, 'W1021': 245, 'W5220': 246, 'W2899': 247, 'W46': 248, 'W221': 249, 'W858': 250, 'W3718': 251, 'W5380': 252, 'W1796': 253, 'W3270': 254, 'W1039': 255, 'W5047': 256, 'W2607': 257, 'W3428': 258, 'W3146': 259, 'W173': 260, 'W1988': 261, 'W322': 262, 'W2451': 263, 'W4567': 264, 'W2372': 265, 'W1731': 266, 'W552': 267, 'W851': 268, 'W1428': 269, 'W1960': 270, 'W319': 271, 'W2584': 272, 'W778': 273, 'W1188': 274, 'W430': 275, 'W667': 276, 'W1131': 277, 'W2893': 278, 'W288': 279, 'W253': 280, 'W3154': 281, 'W1397': 282, 'W5392': 283, 'W113': 284, 'W943': 285, 'W297': 286, 'W1338': 287, 'W354': 288, 'W763': 289, 'W3010': 290, 'W3264': 291, 'W2544': 292, 'W293': 293, 'W149': 294, 'W1702': 295, 'W3187': 296, 'W58': 297, 'W512': 298, 'W3613': 299, 'W3693': 300, 'W246': 301, 'W291': 302, 'W24': 303, 'W1191': 304, 'W1966': 305, 'W800': 306, 'W2892': 307, 'W1637': 308, 'W54': 309, 'W421': 310, 'W132': 311, 'W1035': 312, 'W4525': 313, 'W5278': 314, 'W5234': 315, 'W81': 316, 'W50': 317, 'W235': 318, 'W3012': 319, 'W290': 320, 'W646': 321, 'W2261': 322, 'W3325': 323, 'W494': 324, 'W1643': 325, 'W358': 326, 'W224': 327, 'W1732': 328, 'W1203': 329, 'W2228': 330, 'W5230': 331, 'W3804': 332, 'W797': 333, 'W441': 334, 'W2071': 335, 'W302': 336, 'W1017': 337, 'W70': 338, 'W457': 339, 'W180': 340, 'W7': 341, 'W3074': 342, 'W5107': 343, 'W5331': 344, 'W639': 345, 'W5058': 346, 'W3671': 347, 'W2656': 348, 'W1409': 349, 'W3346': 350, 'W1408': 351, 'W905': 352, 'W428': 353, 'W133': 354, 'W949': 355, 'W312': 356, 'W1976': 357, 'W3666': 358, 'W4701': 359, 'W3647': 360, 'W2132': 361, 'W161': 362, 'W254': 363, 'W1086': 364, 'W627': 365, 'W289': 366, 'W2402': 367, 'W4251': 368, 'W1382': 369, 'W3606': 370, 'W55': 371, 'W3297': 372, 'W470': 373, 'W250': 374, 'W1473': 375, 'W1824': 376, 'W1389': 377, 'W2823': 378, 'W1030': 379, 'W228': 380, 'W1582': 381, 'W2133': 382, 'W1316': 383, 'W5390': 384, 'W404': 385, 'W324': 386, 'W630': 387, 'W4563': 388, 'W138': 389, 'W1128': 390, 'W1': 391, 'W4361': 392, 'W2966': 393, 'W1285': 394, 'W2954': 395, 'W2169': 396, 'W3381': 397, 'W978': 398, 'W125': 399, 'W4110': 400, 'W1198': 401, 'W5173': 402, 'W215': 403, 'W3576': 404, 'W1154': 405, 'W1011': 406, 'W3300': 407, 'W462': 408, 'W206': 409, 'W4199': 410, 'W5078': 411, 'W601': 412, 'W790': 413, 'W1798': 414, 'W2078': 415, 'W1003': 416, 'W582': 417, 'W4000': 418, 'W2086': 419, 'W76': 420, 'W150': 421, 'W92': 422, 'W2889': 423, 'W4203': 424, 'W1294': 425, 'W3086': 426, 'W3451': 427, 'W5224': 428, 'W2569': 429, 'W3575': 430, 'W931': 431, 'W4752': 432, 'W498': 433, 'W285': 434, 'W5379': 435, 'W3294': 436, 'W3299': 437, 'W5228': 438, 'W227': 439, 'W5076': 440, 'W2609': 441, 'W3939': 442, 'W115': 443, 'W345': 444, 'W972': 445, 'W1177': 446, 'W1200': 447, 'W694': 448, 'W1339': 449, 'W984': 450, 'W515': 451, 'W4034': 452, 'W2315': 453, 'W4697': 454, 'W5238': 455, 'W437': 456, 'W1192': 457, 'W908': 458, 'W346': 459, 'W56': 460, 'W93': 461, 'W2577': 462, 'W2113': 463, 'W2220': 464, 'W47': 465, 'W45': 466, 'W688': 467, 'W5141': 468, 'W335': 469, 'W2542': 470, 'W2391': 471, 'W3296': 472, 'W1220': 473, 'W1932': 474, 'W1162': 475, 'W1275': 476, 'W3024': 477, 'W657': 478, 'W1115': 479, 'W277': 480, 'W1205': 481, 'W1072': 482, 'W489': 483, 'W881': 484, 'W4068': 485, 'W2292': 486, 'W5024': 487, 'W1141': 488, 'W928': 489, 'W427': 490, 'W128': 491, 'W2360': 492, 'W2552': 493, 'W5025': 494, 'W2135': 495, 'W5100': 496, 'W597': 497, 'W2580': 498, 'W921': 499, 'W5198': 500, 'W5077': 501, 'W725': 502, 'W106': 503, 'W2107': 504, 'W2355': 505, 'W533': 506, 'W3326': 507, 'W2612': 508, 'W3075': 509, 'W1202': 510, 'W1254': 511, 'W452': 512, 'W119': 513, 'W1097': 514, 'W4202': 515, 'W3949': 516, 'W3664': 517, 'W965': 518, 'W1856': 519, 'W2900': 520, 'W953': 521, 'W1751': 522, 'W1513': 523, 'W1010': 524, 'W1129': 525, 'W607': 526, 'W205': 527, 'W537': 528, 'W218': 529, 'W2870': 530, 'W26': 531, 'W3219': 532, 'W5116': 533, 'W3161': 534, 'W1053': 535, 'W329': 536, 'W4': 537, 'W2158': 538, 'W604': 539, 'W110': 540, 'W2251': 541, 'W139': 542, 'W3522': 543, 'W4147': 544, 'W2611': 545, 'W49': 546, 'W1723': 547, 'W2378': 548, 'W950': 549, 'W2344': 550, 'W5008': 551, 'W222': 552, 'W721': 553, 'W2187': 554, 'W1105': 555, 'W3002': 556, 'W649': 557, 'W1632': 558, 'W383': 559, 'W314': 560, 'W104': 561, 'W1305': 562, 'W417': 563, 'W351': 564, 'W1361': 565, 'W2015': 566, 'W2339': 567, 'W1027': 568, 'W940': 569, 'W3550': 570, 'W3358': 571, 'W91': 572, 'W130': 573, 'W5378': 574, 'W2498': 575, 'W38': 576, 'W3929': 577, 'W1848': 578, 'W3016': 579, 'W287': 580, 'W2039': 581, 'W5377': 582, 'W122': 583, 'W5386': 584, 'W3691': 585, 'W2581': 586, 'W1145': 587, 'W124': 588, 'W4480': 589, 'W1211': 590, 'W901': 591, 'W349': 592, 'W280': 593, 'W370': 594, 'W414': 595, 'W3615': 596, 'W633': 597, 'W1757': 598, 'W503': 599, 'W1636': 600, 'W1379': 601, 'W385': 602, 'W2697': 603, 'W609': 604, 'W1262': 605, 'W660': 606, 'W927': 607, 'W1195': 608, 'W418': 609, 'W722': 610, 'W338': 611, 'W505': 612, 'W3141': 613, 'W419': 614, 'W1065': 615, 'W774': 616, 'W4696': 617, 'W1548': 618, 'W1160': 619, 'W1789': 620, 'W951': 621, 'W89': 622, 'W2242': 623, 'W447': 624, 'W59': 625, 'W2608': 626, 'W2478': 627, 'W1216': 628, 'W214': 629, 'W4351': 630, 'W904': 631, 'W330': 632, 'W835': 633, 'W1120': 634, 'W1571': 635, 'W336': 636, 'W4331': 637, 'W2061': 638, 'W3324': 639, 'W3755': 640, 'W736': 641, 'W3194': 642, 'W39': 643, 'W1101': 644, 'W347': 645, 'W4966': 646, 'W1770': 647, 'W955': 648, 'W469': 649, 'W1014': 650, 'W3122': 651, 'W5258': 652, 'W416': 653, 'W2750': 654, 'W2637': 655, 'W2273': 656, 'W308': 657, 'W5383': 658, 'W2048': 659, 'W615': 660, 'W1846': 661, 'W983': 662, 'W4119': 663, 'W3681': 664, 'W2160': 665, 'W776': 666, 'W2583': 667, 'W1315': 668, 'W3640': 669, 'W3329': 670, 'W2379': 671, 'W584': 672, 'W87': 673, 'W2987': 674, 'W392': 675, 'W97': 676, 'W244': 677, 'W731': 678, 'W2131': 679, 'W574': 680, 'W5085': 681, 'W2696': 682, 'W68': 683, 'W900': 684, 'W2783': 685, 'W388': 686, 'W3280': 687, 'W3953': 688, 'W4492': 689, 'W152': 690, 'W2060': 691, 'W1383': 692, 'W707': 693, 'W5': 694, 'W3183': 695, 'W472': 696, 'W2192': 697, 'W5295': 698, 'W1041': 699, 'W238': 700, 'W1117': 701, 'W2582': 702, 'W2741': 703, 'W305': 704, 'W4464': 705, 'W2602': 706, 'W920': 707, 'W183': 708, 'W806': 709, 'W2890': 710, 'W3422': 711, 'W4396': 712, 'W3070': 713, 'W245': 714, 'W3750': 715, 'W2020': 716, 'W553': 717, 'W2035': 718, 'W651': 719, 'W5009': 720, 'W337': 721, 'W560': 722, 'W37': 723, 'W5342': 724, 'W1776': 725, 'W57': 726, 'W1186': 727, 'W4066': 728, 'W2896': 729, 'W3229': 730, 'W350': 731, 'W1130': 732, 'W804': 733, 'W363': 734, 'W550': 735, 'W2776': 736, 'W3653': 737, 'W1372': 738, 'W1213': 739, 'W333': 740, 'W1983': 741, 'W526': 742, 'W934': 743, 'W979': 744, 'W1411': 745, 'W5226': 746, 'W158': 747, 'W1722': 748, 'W3706': 749, 'W120': 750, 'W409': 751, 'W4627': 752, 'W43': 753, 'W4605': 754, 'W16': 755, 'W4721': 756, 'W4524': 757, 'W187': 758, 'W747': 759, 'W593': 760, 'W2677': 761, 'W1004': 762, 'W3406': 763, 'W2': 764, 'W1991': 765, 'W2429': 766, 'W3301': 767, 'W1527': 768, 'W321': 769, 'W397': 770, 'W1573': 771, 'W5268': 772, 'W5075': 773, 'W1467': 774, 'W34': 775, 'W1043': 776, 'W4532': 777, 'W154': 778, 'W1488': 779, 'W62': 780, 'W963': 781, 'W1674': 782, 'W1032': 783, 'W5223': 784, 'W644': 785, 'W5274': 786, 'W3826': 787, 'W1161': 788, 'W1553': 789, 'W540': 790, 'W803': 791, 'W4526': 792, 'W3699': 793, 'W1667': 794, 'W2765': 795, 'W2345': 796, 'W708': 797, 'W109': 798, 'W689': 799, 'W1440': 800, 'W286': 801, 'W890': 802, 'W1078': 803, 'W937': 804, 'W3218': 805, 'W493': 806, 'W3344': 807, 'W4082': 808, 'W386': 809, 'W1209': 810, 'W2008': 811, 'W18': 812, 'W2509': 813, 'W795': 814, 'W1727': 815, 'W5221': 816, 'W2576': 817, 'W1079': 818, 'W5124': 819, 'W746': 820, 'W2079': 821, 'W226': 822, 'W2940': 823, 'W1363': 824, 'W1110': 825, 'W2775': 826, 'W1857': 827, 'W2588': 828, 'W2485': 829, 'W2418': 830, 'W2578': 831, 'W495': 832, 'W377': 833, 'W5196': 834, 'W15': 835, 'W4575': 836, 'W1276': 837, 'W204': 838, 'W1075': 839, 'W488': 840, 'W5384': 841, 'W5082': 842, 'W4352': 843, 'W1248': 844, 'W791': 845, 'W1419': 846, 'W932': 847, 'W1119': 848, 'W1524': 849, 'W1730': 850, 'W263': 851, 'W270': 852, 'W556': 853, 'W3518': 854, 'W967': 855, 'W212': 856, 'W2181': 857, 'W1277': 858, 'W5053': 859, 'W134': 860, 'W2579': 861, 'W25': 862, 'W2606': 863, 'W127': 864, 'W5231': 865, 'W592': 866, 'W2009': 867, 'W4262': 868, 'W2446': 869, 'W634': 870, 'W1138': 871, 'W429': 872, 'W1197': 873, 'W754': 874, 'W3506': 875, 'W802': 876, 'W249': 877, 'W3572': 878, 'W4273': 879, 'W278': 880, 'W434': 881, 'W3287': 882, 'W1895': 883, 'W326': 884, 'W4359': 885, 'W765': 886, 'W5283': 887, 'W426': 888, 'W1146': 889, 'W787': 890, 'W1196': 891, 'W666': 892, 'W1094': 893, 'W399': 894, 'W4700': 895, 'W3860': 896, 'W926': 897, 'W755': 898, 'W875': 899, 'W1357': 900, 'W703': 901, 'W5079': 902, 'W3849': 903, 'W4232': 904, 'W2869': 905, 'W1099': 906, 'W1362': 907, 'W400': 908, 'W874': 909, 'W3284': 910, 'W866': 911, 'W617': 912, 'W1580': 913, 'W1273': 914, 'W1296': 915, 'W636': 916, 'W95': 917, 'W5355': 918, 'W5086': 919, 'W559': 920, 'W658': 921, 'W3404': 922, 'W5387': 923, 'W786': 924, 'W2214': 925, 'W5233': 926, 'W2077': 927, 'W2340': 928, 'W188': 929, 'W1398': 930, 'W2591': 931, 'W3553': 932, 'W2692': 933, 'W100': 934, 'W1471': 935, 'W4463': 936, 'W98': 937, 'W3535': 938, 'W977': 939, 'W3814': 940, 'W5222': 941, 'W12': 942, 'W1373': 943, 'W2573': 944, 'W1818': 945, 'W42': 946, 'W5144': 947, 'W4407': 948, 'W3394': 949, 'W5205': 950, 'W1124': 951, 'W3000': 952, 'W1512': 953, 'W4158': 954, 'W3165': 955, 'W1140': 956, 'W1235': 957, 'W52': 958, 'W281': 959, 'W5176': 960, 'W2568': 961, 'W1399': 962, 'W2407': 963, 'W3011': 964, 'W2658': 965, 'W952': 966, 'W580': 967, 'W836': 968, 'W2732': 969, 'W438': 970, 'W2139': 971, 'W5229': 972, 'W1954': 973, 'W867': 974, 'W3206': 975, 'W114': 976, 'W367': 977, 'W3286': 978, 'W1514': 979, 'W1206': 980, 'W925': 981, 'W1093': 982, 'W4719': 983, 'W4196': 984, 'W5080': 985, 'W13': 986, 'W4684': 987, 'W411': 988, 'W461': 989, 'W1890': 990, 'W968': 991, 'W1968': 992, 'W861': 993, 'W160': 994, 'W555': 995, 'W283': 996, 'W306': 997, 'W910': 998, 'W5019': 999, 'W5084': 1000, 'W588': 1001, 'W375': 1002, 'W433': 1003, 'W1144': 1004, 'W1388': 1005, 'W78': 1006, 'W391': 1007, 'W28': 1008, 'W911': 1009, 'W2730': 1010, 'W5081': 1011, 'W1364': 1012, 'W3275': 1013, 'W1820': 1014, 'W3635': 1015, 'W4081': 1016, 'W2654': 1017, 'W10': 1018, 'W145': 1019, 'W640': 1020, 'W1747': 1021, 'W749': 1022, 'W2321': 1023, 'W435': 1024, 'W3628': 1025, 'W1181': 1026, 'W1109': 1027, 'W230': 1028, 'W317': 1029, 'W4469': 1030, 'W5020': 1031, 'W5052': 1032, 'W159': 1033, 'W939': 1034, 'W2051': 1035, 'W299': 1036, 'W389': 1037, 'W3892': 1038, 'W88': 1039, 'W275': 1040, 'W5119': 1041, 'W1044': 1042, 'W5152': 1043, 'W2507': 1044, 'W328': 1045, 'W1810': 1046, 'W1401': 1047, 'W3689': 1048, 'W203': 1049, 'W2277': 1050, 'W111': 1051, 'W1987': 1052, 'W405': 1053, 'W51': 1054, 'W608': 1055, 'W292': 1056, 'W1509': 1057, 'W2587': 1058, 'W387': 1059, 'W3068': 1060, 'W3484': 1061, 'W1603': 1062, 'W577': 1063, 'W5337': 1064, 'W468': 1065, 'W2936': 1066, 'W2106': 1067, 'W84': 1068, 'W5279': 1069, 'W1738': 1070, 'W2574': 1071, 'W3577': 1072, 'W1298': 1073, 'W1264': 1074, 'W3933': 1075}\n",
            "1076\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# transform all the symbol sequence into one-hot representation\n",
        "zero_vec = torch.zeros(len_symbol_sequence)\n",
        "zero_vec[0] = 1\n",
        "one_hot_dict = {'unknown': zero_vec}\n",
        "\n",
        "for key, value in word_dict_1.items():\n",
        "    one_hot_key = torch.zeros(len_symbol_sequence)\n",
        "    one_hot_key[value] = 1\n",
        "    one_hot_dict[key] = one_hot_key\n",
        "\n",
        "print(one_hot_dict)\n",
        "print(len(one_hot_dict))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0KmvWObr8Wz9",
        "outputId": "5c03599c-7c1a-4936-8049-4bd5c304b293"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'unknown': tensor([1., 0., 0.,  ..., 0., 0., 0.]), 'W2554': tensor([0., 1., 0.,  ..., 0., 0., 0.]), 'W446': tensor([0., 0., 1.,  ..., 0., 0., 0.]), 'W2486': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W155': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W930': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W4462': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W568': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W412': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W809': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W3852': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W4706': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W4665': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W3167': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2832': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2068': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W973': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W300': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W5376': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W801': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1061': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W5118': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W66': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W5227': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W252': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W170': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W5381': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W4495': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2232': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2329': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2055': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W5389': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2929': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2189': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1365': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W408': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W216': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1125': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1926': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W3117': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W53': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W3968': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W4789': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1586': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W3384': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W5330': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W223': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W3948': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W3169': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2961': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W83': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1368': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W5267': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1832': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W5414': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W844': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W105': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1343': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W217': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W3526': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1242': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W3306': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W641': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W496': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W5115': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W528': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W3625': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W654': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W264': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W325': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W4682': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1982': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2567': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2094': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W219': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W6': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1450': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1775': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W3690': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2026': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W5415': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1335': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2955': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W5282': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W108': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W334': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W69': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2678': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W3954': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W341': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W4513': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2227': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W432': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2575': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W401': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2570': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W213': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W954': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W5277': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W506': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2897': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W5242': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2052': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W855': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1127': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W4537': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W340': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W395': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1174': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1601': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2599': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W225': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W5232': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1210': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2047': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W848': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1658': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1707': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W31': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W3265': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W3761': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1020': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W310': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W17': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W220': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2982': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W35': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W748': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1058': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W4135': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W3263': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2610': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W27': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W507': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W5329': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W626': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2898': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1375': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1562': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W663': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W642': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W912': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1038': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W5206': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1270': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2210': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W4756': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W4172': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2463': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2423': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W168': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W3530': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W659': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1990': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W616': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W3692': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W516': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W141': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W3668': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W456': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W532': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W5120': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W933': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1536': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W4391': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W873': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W259': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W344': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W357': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1904': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1769': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W131': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W398': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W3942': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W5218': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W909': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W5281': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W376': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W4283': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2586': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W5371': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W32': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W3248': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W5083': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W64': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W5117': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1280': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W4705': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2200': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W3290': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W379': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W3714': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W19': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W67': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1312': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1074': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2743': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W3188': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W374': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W475': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2253': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W5385': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W5375': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W840': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W665': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W679': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W307': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W36': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1515': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1085': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W903': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W4981': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W94': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W90': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W480': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W982': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W3931': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1253': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W548': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W348': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2036': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W369': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2348': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W566': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W3069': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W647': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W167': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W5293': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1165': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W112': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W5044': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W3279': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1692': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W117': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W3156': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W137': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2757': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1477': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W301': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1395': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1984': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1606': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W3739': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W406': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W4078': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1021': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W5220': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2899': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W46': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W221': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W858': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W3718': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W5380': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1796': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W3270': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1039': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W5047': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2607': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W3428': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W3146': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W173': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1988': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W322': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2451': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W4567': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2372': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1731': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W552': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W851': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1428': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1960': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W319': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2584': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W778': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1188': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W430': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W667': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1131': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2893': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W288': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W253': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W3154': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1397': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W5392': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W113': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W943': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W297': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1338': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W354': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W763': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W3010': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W3264': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2544': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W293': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W149': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1702': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W3187': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W58': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W512': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W3613': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W3693': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W246': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W291': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W24': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1191': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1966': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W800': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2892': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1637': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W54': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W421': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W132': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1035': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W4525': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W5278': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W5234': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W81': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W50': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W235': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W3012': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W290': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W646': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2261': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W3325': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W494': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1643': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W358': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W224': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1732': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1203': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2228': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W5230': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W3804': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W797': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W441': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2071': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W302': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1017': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W70': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W457': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W180': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W7': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W3074': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W5107': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W5331': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W639': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W5058': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W3671': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2656': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1409': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W3346': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1408': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W905': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W428': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W133': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W949': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W312': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1976': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W3666': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W4701': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W3647': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2132': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W161': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W254': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1086': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W627': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W289': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2402': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W4251': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1382': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W3606': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W55': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W3297': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W470': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W250': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1473': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1824': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1389': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2823': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1030': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W228': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1582': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2133': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1316': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W5390': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W404': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W324': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W630': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W4563': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W138': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1128': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W4361': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2966': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1285': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2954': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2169': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W3381': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W978': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W125': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W4110': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1198': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W5173': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W215': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W3576': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1154': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1011': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W3300': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W462': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W206': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W4199': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W5078': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W601': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W790': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1798': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2078': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1003': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W582': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W4000': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2086': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W76': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W150': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W92': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2889': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W4203': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1294': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W3086': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W3451': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W5224': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2569': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W3575': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W931': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W4752': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W498': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W285': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W5379': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W3294': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W3299': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W5228': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W227': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W5076': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2609': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W3939': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W115': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W345': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W972': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1177': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1200': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W694': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1339': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W984': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W515': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W4034': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2315': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W4697': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W5238': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W437': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1192': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W908': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W346': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W56': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W93': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2577': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2113': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2220': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W47': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W45': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W688': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W5141': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W335': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2542': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2391': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W3296': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1220': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1932': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1162': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1275': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W3024': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W657': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1115': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W277': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1205': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1072': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W489': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W881': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W4068': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2292': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W5024': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1141': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W928': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W427': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W128': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2360': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2552': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W5025': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2135': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W5100': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W597': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2580': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W921': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W5198': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W5077': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W725': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W106': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2107': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2355': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W533': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W3326': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2612': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W3075': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1202': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1254': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W452': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W119': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1097': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W4202': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W3949': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W3664': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W965': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1856': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2900': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W953': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1751': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1513': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1010': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1129': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W607': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W205': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W537': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W218': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2870': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W26': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W3219': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W5116': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W3161': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1053': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W329': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W4': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2158': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W604': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W110': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2251': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W139': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W3522': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W4147': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2611': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W49': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1723': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2378': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W950': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2344': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W5008': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W222': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W721': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2187': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1105': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W3002': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W649': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1632': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W383': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W314': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W104': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1305': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W417': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W351': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1361': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2015': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2339': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1027': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W940': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W3550': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W3358': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W91': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W130': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W5378': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2498': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W38': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W3929': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1848': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W3016': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W287': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2039': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W5377': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W122': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W5386': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W3691': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2581': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1145': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W124': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W4480': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1211': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W901': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W349': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W280': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W370': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W414': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W3615': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W633': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1757': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W503': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1636': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1379': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W385': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2697': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W609': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1262': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W660': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W927': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1195': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W418': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W722': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W338': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W505': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W3141': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W419': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1065': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W774': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W4696': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1548': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1160': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1789': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W951': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W89': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2242': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W447': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W59': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2608': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2478': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1216': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W214': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W4351': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W904': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W330': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W835': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1120': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1571': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W336': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W4331': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2061': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W3324': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W3755': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W736': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W3194': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W39': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1101': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W347': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W4966': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1770': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W955': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W469': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1014': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W3122': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W5258': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W416': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2750': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2637': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2273': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W308': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W5383': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2048': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W615': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1846': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W983': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W4119': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W3681': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2160': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W776': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2583': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1315': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W3640': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W3329': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2379': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W584': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W87': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2987': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W392': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W97': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W244': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W731': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2131': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W574': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W5085': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2696': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W68': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W900': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2783': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W388': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W3280': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W3953': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W4492': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W152': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2060': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1383': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W707': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W5': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W3183': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W472': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2192': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W5295': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1041': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W238': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1117': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2582': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2741': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W305': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W4464': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2602': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W920': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W183': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W806': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2890': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W3422': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W4396': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W3070': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W245': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W3750': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2020': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W553': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2035': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W651': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W5009': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W337': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W560': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W37': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W5342': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1776': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W57': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1186': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W4066': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2896': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W3229': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W350': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1130': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W804': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W363': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W550': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2776': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W3653': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1372': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1213': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W333': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1983': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W526': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W934': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W979': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1411': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W5226': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W158': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1722': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W3706': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W120': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W409': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W4627': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W43': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W4605': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W16': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W4721': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W4524': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W187': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W747': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W593': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2677': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1004': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W3406': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1991': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2429': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W3301': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1527': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W321': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W397': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1573': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W5268': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W5075': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1467': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W34': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1043': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W4532': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W154': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1488': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W62': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W963': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1674': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1032': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W5223': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W644': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W5274': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W3826': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1161': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1553': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W540': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W803': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W4526': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W3699': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1667': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2765': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2345': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W708': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W109': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W689': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1440': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W286': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W890': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1078': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W937': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W3218': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W493': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W3344': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W4082': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W386': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1209': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2008': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W18': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2509': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W795': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1727': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W5221': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2576': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1079': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W5124': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W746': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2079': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W226': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2940': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1363': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1110': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2775': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1857': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2588': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2485': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2418': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2578': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W495': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W377': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W5196': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W15': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W4575': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1276': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W204': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1075': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W488': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W5384': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W5082': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W4352': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1248': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W791': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1419': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W932': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1119': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1524': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1730': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W263': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W270': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W556': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W3518': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W967': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W212': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2181': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1277': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W5053': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W134': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2579': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W25': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2606': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W127': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W5231': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W592': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2009': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W4262': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2446': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W634': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1138': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W429': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1197': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W754': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W3506': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W802': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W249': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W3572': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W4273': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W278': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W434': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W3287': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1895': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W326': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W4359': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W765': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W5283': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W426': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1146': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W787': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1196': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W666': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1094': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W399': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W4700': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W3860': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W926': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W755': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W875': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1357': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W703': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W5079': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W3849': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W4232': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2869': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1099': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1362': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W400': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W874': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W3284': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W866': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W617': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1580': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1273': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1296': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W636': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W95': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W5355': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W5086': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W559': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W658': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W3404': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W5387': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W786': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2214': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W5233': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2077': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2340': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W188': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1398': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2591': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W3553': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2692': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W100': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1471': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W4463': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W98': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W3535': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W977': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W3814': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W5222': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W12': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1373': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2573': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1818': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W42': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W5144': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W4407': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W3394': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W5205': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1124': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W3000': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1512': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W4158': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W3165': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1140': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1235': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W52': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W281': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W5176': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2568': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1399': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2407': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W3011': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2658': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W952': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W580': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W836': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2732': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W438': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2139': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W5229': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1954': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W867': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W3206': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W114': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W367': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W3286': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1514': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1206': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W925': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1093': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W4719': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W4196': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W5080': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W13': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W4684': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W411': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W461': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1890': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W968': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1968': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W861': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W160': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W555': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W283': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W306': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W910': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W5019': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W5084': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W588': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W375': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W433': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1144': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1388': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W78': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W391': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W28': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W911': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2730': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W5081': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1364': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W3275': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1820': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W3635': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W4081': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2654': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W10': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W145': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W640': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1747': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W749': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2321': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W435': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W3628': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1181': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1109': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W230': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W317': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W4469': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W5020': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W5052': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W159': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W939': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2051': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W299': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W389': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W3892': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W88': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W275': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W5119': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1044': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W5152': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2507': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W328': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1810': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1401': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W3689': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W203': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2277': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W111': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1987': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W405': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W51': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W608': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W292': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1509': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2587': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W387': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W3068': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W3484': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1603': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W577': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W5337': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W468': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2936': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2106': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W84': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W5279': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1738': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W2574': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W3577': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'W1298': tensor([0., 0., 0.,  ..., 1., 0., 0.]), 'W1264': tensor([0., 0., 0.,  ..., 0., 1., 0.]), 'W3933': tensor([0., 0., 0.,  ..., 0., 0., 1.])}\n",
            "1076\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### set the dimension size of embedding"
      ],
      "metadata": {
        "id": "fiX0ipBniIvN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_num = 1000"
      ],
      "metadata": {
        "id": "kUiMWDovVS3e"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# embedding vector - xavier intialization\n",
        "# look_up_table = nn.init.xavier_uniform_(torch.empty(len(word_dict_1), embedding_num))\n",
        "\n",
        "# embedding vector - He intialization\n",
        "look_up_table = nn.init.kaiming_uniform_(torch.empty(len(word_dict_1), embedding_num, requires_grad = True))\n",
        "\n",
        "print(look_up_table)\n",
        "print(look_up_table.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_bbV4apVORQ",
        "outputId": "44bcbc95-3cad-4eb1-9529-fe1c59351205"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.0020,  0.0505, -0.0185,  ...,  0.0597, -0.0629,  0.0542],\n",
            "        [ 0.0294,  0.0275, -0.0711,  ..., -0.0078, -0.0599, -0.0371],\n",
            "        [ 0.0263, -0.0314, -0.0467,  ...,  0.0257,  0.0114, -0.0454],\n",
            "        ...,\n",
            "        [-0.0034,  0.0215,  0.0036,  ..., -0.0246,  0.0444, -0.0004],\n",
            "        [ 0.0650,  0.0032,  0.0181,  ...,  0.0693, -0.0425, -0.0032],\n",
            "        [-0.0682,  0.0116, -0.0497,  ...,  0.0640,  0.0643, -0.0635]],\n",
            "       requires_grad=True)\n",
            "torch.Size([1076, 1000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "category_dict = {'D1': 0, 'D3': 1, 'D4': 2, 'D5': 3, 'D6': 4, 'D7': 5, 'D11': 6, 'D12': 7, 'D13': 8, 'D15': 9, 'D16': 10,\n",
        "                 'D17': 11, 'D18': 12, 'D19': 13, 'D20': 14, 'D21': 15, 'D27': 16, 'D28': 17, 'D32': 18}\n",
        "dict_category = {0: 'D1', 1: 'D3', 2: 'D4', 3: 'D5', 4: 'D6', 5: 'D7', 6: 'D11', 7: 'D12', 8: 'D13', 9: 'D15', 10: 'D16',\n",
        "                 11: 'D17', 12: 'D18', 13: 'D19', 14: 'D20', 15: 'D21', 16: 'D27', 17: 'D28', 18: 'D32'}"
      ],
      "metadata": {
        "id": "Ur5WIy4C6HN9"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_y = torch.zeros(train_len, 19) # torch tensor (900, )\n",
        "for idx, value in enumerate(train_y_list):\n",
        "    tmp = torch.zeros(19)\n",
        "    tmp[category_dict[value]] = 1\n",
        "    train_y[idx] = tmp\n",
        "print(train_y)\n",
        "print(train_y.shape)"
      ],
      "metadata": {
        "id": "_xdj2_sB4LGt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7dcd6f0c-277b-4553-8718-613dcbee19dc"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
            "torch.Size([900, 19])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Vectorize symbol sequence & 4. Padding (set different input length being same: add zero vector)"
      ],
      "metadata": {
        "id": "ZnfKt0nt3_Z5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transform train input's symbol sequence into one-hot vector tensor"
      ],
      "metadata": {
        "id": "LfGC8cAJSoB6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_x = torch.zeros((train_len, 20, len_symbol_sequence)) # (900, 20, 1076), maximum_length of sequence was given to be 20.\n",
        "print(train_x.shape)"
      ],
      "metadata": {
        "id": "-TA6WSZC30HZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ccac03fc-53c9-4524-8ca4-123961466420"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([900, 20, 1076])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def word_to_vec(sequence):\n",
        "    if len(sequence) > 20:\n",
        "        sequence = sequence[:20]\n",
        "    elif len(sequence) < 20:\n",
        "        tmp = ['unknown'] * (20 - len(sequence))\n",
        "        sequence.extend(tmp)\n",
        "\n",
        "    res = torch.zeros((20, len_symbol_sequence))\n",
        "    \n",
        "    for i in range(20):\n",
        "        if sequence[i] in one_hot_dict: # if this word is in the word dictionary,\n",
        "            res[i] = one_hot_dict[sequence[i]]\n",
        "        else: # if this word's frequency is 1 so excluded from word dictionary,\n",
        "            res[i] = one_hot_dict['unknown']\n",
        "    \n",
        "    return res"
      ],
      "metadata": {
        "id": "kSv16Dnx30Dy"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make final train_x tensor\n",
        "\n",
        "for idx, sequence in enumerate(train_x_list):\n",
        "    train_x[idx] = word_to_vec(sequence)\n",
        "\n",
        "print(train_x)\n",
        "print(train_x.shape)"
      ],
      "metadata": {
        "id": "GzkMZElU30DT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "081df213-8d47-4e40-9cb5-e218c4617a13"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         ...,\n",
            "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [1., 0., 0.,  ..., 0., 0., 0.]],\n",
            "\n",
            "        [[1., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         ...,\n",
            "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [1., 0., 0.,  ..., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         ...,\n",
            "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [1., 0., 0.,  ..., 0., 0., 0.]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         ...,\n",
            "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [1., 0., 0.,  ..., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
            "         ...,\n",
            "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [1., 0., 0.,  ..., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         ...,\n",
            "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [1., 0., 0.,  ..., 0., 0., 0.]]])\n",
            "torch.Size([900, 20, 1076])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Make test data's symbol sequence into one-hot vector embedding"
      ],
      "metadata": {
        "id": "FBqvazx2S2Nz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_x = torch.zeros((test_len, 20, len_symbol_sequence)) # (100, 20, 1076)\n",
        "print(test_x.shape)"
      ],
      "metadata": {
        "id": "GYJTdlsg4E5-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d93777d5-e51d-4bae-b7dd-abde1c99025d"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([100, 20, 1076])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# make final test_x tensor\n",
        "\n",
        "for idx, sequence in enumerate(test_x_list):\n",
        "    test_x[idx] = word_to_vec(sequence)"
      ],
      "metadata": {
        "id": "2WgSm8G24E5b"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_x)\n",
        "print(test_x.shape)"
      ],
      "metadata": {
        "id": "OyS-t7qh4E1f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4be904f-1e17-4fd6-cf66-f5290d3542b6"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         ...,\n",
            "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [1., 0., 0.,  ..., 0., 0., 0.]],\n",
            "\n",
            "        [[1., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         ...,\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [1., 0., 0.,  ..., 0., 0., 0.]],\n",
            "\n",
            "        [[1., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         ...,\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         ...,\n",
            "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [1., 0., 0.,  ..., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         ...,\n",
            "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [1., 0., 0.,  ..., 0., 0., 0.]],\n",
            "\n",
            "        [[1., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         ...,\n",
            "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [1., 0., 0.,  ..., 0., 0., 0.]]])\n",
            "torch.Size([100, 20, 1076])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Design 3-layer feedforward network"
      ],
      "metadata": {
        "id": "0PfvGE0X4JZd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.nn.init as init\n",
        "import math\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "from sklearn.metrics import average_precision_score"
      ],
      "metadata": {
        "id": "tGW1ZwgeR7bW"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "print(\"device: \", device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "odzB90bIrGfb",
        "outputId": "1587b33b-f3e0-417e-8da7-af7f7f1c9cba"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "device:  cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# look_up_table.requires_grad = True\n",
        "print(look_up_table)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G1QuALkBLvLF",
        "outputId": "7eef6aa4-15f3-414a-b39c-59a911ac6520"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.0020,  0.0505, -0.0185,  ...,  0.0597, -0.0629,  0.0542],\n",
            "        [ 0.0294,  0.0275, -0.0711,  ..., -0.0078, -0.0599, -0.0371],\n",
            "        [ 0.0263, -0.0314, -0.0467,  ...,  0.0257,  0.0114, -0.0454],\n",
            "        ...,\n",
            "        [-0.0034,  0.0215,  0.0036,  ..., -0.0246,  0.0444, -0.0004],\n",
            "        [ 0.0650,  0.0032,  0.0181,  ...,  0.0693, -0.0425, -0.0032],\n",
            "        [-0.0682,  0.0116, -0.0497,  ...,  0.0640,  0.0643, -0.0635]],\n",
            "       requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MyModel(nn.Module):\n",
        "    def __init__(self, in_features, num_hid1, num_hid2):\n",
        "        super(MyModel, self).__init__()\n",
        "        \n",
        "        # self.weight_1 = nn.Parameter(nn.init.kaiming_uniform_(torch.empty(num_hid1, in_features))) # He initialization\n",
        "        self.weight_1 = nn.Parameter(nn.init.xavier_uniform_(torch.empty(num_hid1, in_features))) # Xavier initialization\n",
        "        self.embedding = nn.Parameter(nn.init.kaiming_uniform_(torch.empty(len(word_dict_1), embedding_num))) # He initialization\n",
        "        self.bias_1 = nn.Parameter(torch.empty(num_hid1))\n",
        "        fan_in, _ = init._calculate_fan_in_and_fan_out(self.embedding)\n",
        "        bound = 1 / math.sqrt(fan_in) if fan_in > 0 else 0\n",
        "        init.uniform_(self.bias_1, -bound, bound)\n",
        "\n",
        "        # self.weight_2 = nn.Parameter(nn.init.kaiming_uniform_(torch.empty(num_hid2, num_hid1))) # He initialization\n",
        "        self.weight_2 = nn.Parameter(nn.init.xavier_uniform_(torch.empty(num_hid2, num_hid1))) # Xavier initialization\n",
        "        self.bias_2 = nn.Parameter(torch.empty(num_hid2))\n",
        "        fan_in, _ = init._calculate_fan_in_and_fan_out(self.weight_2)\n",
        "        bound = 1 / math.sqrt(fan_in) if fan_in > 0 else 0\n",
        "        init.uniform_(self.bias_2, -bound, bound)\n",
        "\n",
        "        # self.weight_3 = nn.Parameter(nn.init.kaiming_uniform_(torch.empty(19, num_hid2))) # He initialization\n",
        "        self.weight_3 = nn.Parameter(nn.init.xavier_uniform_(torch.empty(19, num_hid2))) # Xavier initialization\n",
        "        self.bias_3 = nn.Parameter(torch.empty(19))\n",
        "        fan_in, _ = init._calculate_fan_in_and_fan_out(self.weight_3)\n",
        "        bound = 1 / math.sqrt(fan_in) if fan_in > 0 else 0\n",
        "        init.uniform_(self.bias_3, -bound, bound)\n",
        "\n",
        "        self.bn_1 = nn.BatchNorm1d(num_hid1)\n",
        "        self.bn_2 = nn.BatchNorm1d(num_hid2)\n",
        "\n",
        "        self.sigmoid_function = nn.Sigmoid()\n",
        "    \n",
        "    def forward(self, inputs):\n",
        "        # inputs: (batch_size, max_length * 1076)\n",
        "        input_shape = inputs.shape # (30, 20, 1076)\n",
        "        input = (torch.mm(inputs.flatten(0, 1), self.embedding).reshape(input_shape[0], input_shape[1], -1)).flatten(1,2)\n",
        "\n",
        "        out = torch.mm(input, self.weight_1.T) + self.bias_1\n",
        "        out = self.bn_1(out)\n",
        "        out = self.sigmoid_function(out)\n",
        "\n",
        "        out = torch.mm(out, self.weight_2.T) + self.bias_2\n",
        "        out = self.bn_2(out)\n",
        "        out = self.sigmoid_function(out)\n",
        "\n",
        "        out = torch.mm(out, self.weight_3.T) + self.bias_3\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "id": "S_DwMx1j4JO8"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Model\n",
        "input_size = embedding_num * 20\n",
        "num_hid1 = 1000\n",
        "num_hid2 = 100\n",
        "\n",
        "model = MyModel(input_size, num_hid1, num_hid2).to(device)"
      ],
      "metadata": {
        "id": "cxJ8l93h4JLT"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.embedding)\n",
        "print(model.embedding.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y32jaqkYSSzK",
        "outputId": "0e7e1419-a380-475c-aa64-736522e68ec1"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[-0.0679,  0.0073,  0.0374,  ..., -0.0324, -0.0043,  0.0141],\n",
            "        [ 0.0396,  0.0250, -0.0757,  ...,  0.0374, -0.0295,  0.0393],\n",
            "        [-0.0361,  0.0337, -0.0329,  ...,  0.0011,  0.0569,  0.0378],\n",
            "        ...,\n",
            "        [-0.0357, -0.0558,  0.0531,  ...,  0.0675, -0.0744,  0.0067],\n",
            "        [-0.0671, -0.0580, -0.0261,  ..., -0.0414, -0.0545, -0.0576],\n",
            "        [ 0.0061,  0.0611, -0.0150,  ..., -0.0003, -0.0768,  0.0396]],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "torch.Size([1076, 1000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 0.01\n",
        "weight_decay = 0.99\n",
        "batch_size = 30\n",
        "num_epochs = 15\n",
        "exp_num = 16\n",
        "\n",
        "# Optimizer: Stochastic Gradient Descent\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "# Learning rate scheduler: StepLR\n",
        "# scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, 1, eta_min=0, last_epoch=-1)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.95)\n",
        "# scheduler = optim.lr_scheduler.LambdaLR(optimizer=optimizer,\n",
        "#                                         lr_lambda=lambda epoch: 0.95 ** epoch,\n",
        "#                                         last_epoch=-1,\n",
        "#                                         verbose=False)\n",
        "\n",
        "# Loss: Cross-Entropy Loss\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "lW2csX6z4JKx"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyDataset(data.Dataset):\n",
        "    def __init__(self, x_tensor, y_tensor):\n",
        "        super(MyDataset, self).__init__()\n",
        "\n",
        "        self.x = x_tensor\n",
        "        self.y = y_tensor\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.x)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        return self.x[index], self.y[index]"
      ],
      "metadata": {
        "id": "Cpih2S_z4JGs"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_dataset = MyDataset(train_x, train_y)\n",
        "\n",
        "train_size = int(0.9 * len(my_dataset))\n",
        "test_size = len(my_dataset) - train_size\n",
        "\n",
        "train_dataset, valid_dataset = torch.utils.data.random_split(my_dataset, [train_size, test_size])\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle = True)\n",
        "valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=batch_size, shuffle = False)"
      ],
      "metadata": {
        "id": "s9gfFCVMQ4jZ"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_ap_score(y_true, y_scores):\n",
        "    \"\"\"\n",
        "    Get average precision score between 2 1-d numpy arrays\n",
        "    Args:\n",
        "        y_true: batch of true labels\n",
        "        y_scores: batch of confidence scores\n",
        "=\n",
        "    Returns:\n",
        "        sum of batch average precision\n",
        "    \"\"\"\n",
        "    scores = 0.0\n",
        "\n",
        "    for i in range(y_true.shape[0]):\n",
        "        scores += average_precision_score(y_true=y_true[i], y_score=y_scores[i])\n",
        "\n",
        "    return scores"
      ],
      "metadata": {
        "id": "zf1hZ2X8Q4is"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(look_up_table)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WZHleo3R3qC-",
        "outputId": "2679cb3c-c5f5-4ac8-8c51-9b45ed9f07c7"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.0020,  0.0505, -0.0185,  ...,  0.0597, -0.0629,  0.0542],\n",
            "        [ 0.0294,  0.0275, -0.0711,  ..., -0.0078, -0.0599, -0.0371],\n",
            "        [ 0.0263, -0.0314, -0.0467,  ...,  0.0257,  0.0114, -0.0454],\n",
            "        ...,\n",
            "        [-0.0034,  0.0215,  0.0036,  ..., -0.0246,  0.0444, -0.0004],\n",
            "        [ 0.0650,  0.0032,  0.0181,  ...,  0.0693, -0.0425, -0.0032],\n",
            "        [-0.0682,  0.0116, -0.0497,  ...,  0.0640,  0.0643, -0.0635]],\n",
            "       requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss_list, train_acc_list, val_loss_list, val_acc_list = [], [], [], []\n",
        "best_val_acc = 0.0\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    train_loss = 0.0\n",
        "    train_acc = 0.0\n",
        "    val_loss = 0.0\n",
        "    val_acc = 0.0\n",
        "\n",
        "    model = model.to(device)\n",
        "\n",
        "    ############### Training Phase #############\n",
        "    for idx, (tr_data, tr_label) in enumerate(train_loader):\n",
        "        # data: (10, 20, 1076), label: (10, )\n",
        "        tr_data = tr_data.to(device) # tr_data: (10, 20, 1076)\n",
        "        tr_label = tr_label.to(device)\n",
        "\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        tr_output = model(tr_data)\n",
        "\n",
        "        tr_loss = criterion(tr_output, tr_label)\n",
        "        tr_loss.backward()\n",
        "        optimizer.step()\n",
        "        # scheduler.step()\n",
        "\n",
        "        # look up table update\n",
        "        look_up_table = model.embedding\n",
        "\n",
        "        train_loss += tr_loss.item()\n",
        "        train_acc += get_ap_score(torch.Tensor.cpu(tr_label).detach().numpy(),\n",
        "                                    torch.Tensor.cpu(tr_output).detach().numpy())\n",
        "    \n",
        "    train_num_samples = float(len(train_loader.dataset))\n",
        "    tr_loss_ = train_loss / train_num_samples\n",
        "    tr_acc_ = train_acc / train_num_samples\n",
        "\n",
        "    train_loss_list.append(tr_loss_)\n",
        "    train_acc_list.append(tr_acc_)\n",
        "    \n",
        "    ############### Evaluation Phase #############\n",
        "    for idx, (val_data, val_label) in enumerate(valid_loader):\n",
        "        val_data = val_data.to(device)\n",
        "        val_label = val_label.to(device)\n",
        "\n",
        "        model.eval()\n",
        "\n",
        "        vl_output = model(val_data)\n",
        "\n",
        "        vl_loss = criterion(vl_output, val_label)\n",
        "        val_loss += vl_loss.item()\n",
        "        val_acc += get_ap_score(torch.Tensor.cpu(val_label).detach().numpy(),\n",
        "                                    torch.Tensor.cpu(vl_output).detach().numpy())\n",
        "        \n",
        "    \n",
        "    valid_num_samples = float(len(valid_loader.dataset))\n",
        "    val_loss_ = val_loss / valid_num_samples\n",
        "    val_acc_ = val_acc / valid_num_samples\n",
        "\n",
        "    val_loss_list.append(val_loss_)\n",
        "    val_acc_list.append(val_acc_)\n",
        "\n",
        "    print('\\nEpoch {}, train_loss: {:.4f}, train_acc:{:.3f}, valid_loss: {:.4f}, valid_acc:{:.3f}'.format(epoch, tr_loss_, tr_acc_, val_loss_, val_acc_))\n",
        "    if val_acc_ > best_val_acc:\n",
        "        best_val_acc = val_acc_\n",
        "        torch.save(model.state_dict(), f'./lab1-2_parameters/model_{exp_num}.pth')\n",
        "        print(f'Epoch {epoch} model saved')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ruQkRvFBQ4eu",
        "outputId": "5ea5815a-7b76-4183-8176-2da0981afee0"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 0, train_loss: 0.0664, train_acc:0.551, valid_loss: 0.0555, valid_acc:0.666\n",
            "Epoch 0 model saved\n",
            "\n",
            "Epoch 1, train_loss: 0.0315, train_acc:0.845, valid_loss: 0.0471, valid_acc:0.706\n",
            "Epoch 1 model saved\n",
            "\n",
            "Epoch 2, train_loss: 0.0159, train_acc:0.923, valid_loss: 0.0502, valid_acc:0.674\n",
            "\n",
            "Epoch 3, train_loss: 0.0082, train_acc:0.959, valid_loss: 0.0508, valid_acc:0.691\n",
            "\n",
            "Epoch 4, train_loss: 0.0049, train_acc:0.980, valid_loss: 0.0471, valid_acc:0.685\n",
            "\n",
            "Epoch 5, train_loss: 0.0030, train_acc:0.990, valid_loss: 0.0513, valid_acc:0.669\n",
            "\n",
            "Epoch 6, train_loss: 0.0017, train_acc:0.996, valid_loss: 0.0519, valid_acc:0.688\n",
            "\n",
            "Epoch 7, train_loss: 0.0010, train_acc:0.999, valid_loss: 0.0505, valid_acc:0.694\n",
            "\n",
            "Epoch 8, train_loss: 0.0006, train_acc:1.000, valid_loss: 0.0533, valid_acc:0.688\n",
            "\n",
            "Epoch 9, train_loss: 0.0004, train_acc:1.000, valid_loss: 0.0531, valid_acc:0.689\n",
            "\n",
            "Epoch 10, train_loss: 0.0003, train_acc:1.000, valid_loss: 0.0538, valid_acc:0.689\n",
            "\n",
            "Epoch 11, train_loss: 0.0002, train_acc:1.000, valid_loss: 0.0537, valid_acc:0.684\n",
            "\n",
            "Epoch 12, train_loss: 0.0002, train_acc:1.000, valid_loss: 0.0548, valid_acc:0.677\n",
            "\n",
            "Epoch 13, train_loss: 0.0001, train_acc:1.000, valid_loss: 0.0557, valid_acc:0.706\n",
            "Epoch 13 model saved\n",
            "\n",
            "Epoch 14, train_loss: 0.0001, train_acc:1.000, valid_loss: 0.0555, valid_acc:0.687\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(look_up_table)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B5DaBYDg3ty6",
        "outputId": "515f3c04-e111-4424-d456-61a75111df0a"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[ 0.0268, -0.0170, -0.0571,  ...,  0.0517,  0.0976,  0.0193],\n",
            "        [ 0.1443, -0.0411, -0.0924,  ...,  0.0046, -0.1193,  0.0893],\n",
            "        [-0.0799,  0.0250,  0.0579,  ...,  0.0765,  0.0072,  0.1131],\n",
            "        ...,\n",
            "        [ 0.0256, -0.0218,  0.0668,  ...,  0.0476, -0.1591,  0.0053],\n",
            "        [-0.0314,  0.0496, -0.0253,  ..., -0.0680, -0.0908, -0.1407],\n",
            "        [ 0.0356,  0.1136,  0.0505,  ..., -0.0446, -0.0847,  0.1786]],\n",
            "       device='cuda:0', requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualize train, valid loss and accuracy"
      ],
      "metadata": {
        "id": "2U0c-RieRVmK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epoch_list = list(range(num_epochs))"
      ],
      "metadata": {
        "id": "NfyqNOvpRKLM"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(epoch_list, train_loss_list, 'r', label='Train Loss')\n",
        "plt.plot(epoch_list, val_loss_list, 'b', label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(loc='lower right')\n",
        "# plt.show()\n",
        "plt.savefig(f'./lab1-2_submissions/exp{exp_num}_sch_bn_loss_graph.png')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "UTrW9lFHRKKv",
        "outputId": "c2be076f-3ee7-4001-c32d-eb00bff41a65"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(epoch_list, train_acc_list, 'r', label='Train Accuracy')\n",
        "plt.plot(epoch_list, val_acc_list, 'b', label='Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "# plt.show()\n",
        "plt.savefig(f'./lab1-2_submissions/exp{exp_num}_acc_graph.png')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "TW7mA52vRKGz",
        "outputId": "c8140238-fe06-4541-fb87-b89f78bef474"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test"
      ],
      "metadata": {
        "id": "H5i2SX-qRj6_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_model = MyModel(input_size, num_hid1, num_hid2).to(device)\n",
        "PATH = f'./lab1-2_parameters/model_{exp_num}.pth'\n",
        "print(PATH)\n",
        "test_model.load_state_dict(torch.load(PATH))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3RZBZmggRKC3",
        "outputId": "88b19c48-fd93-43bd-fa03-59a2c19b81c4"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "./lab1-2_parameters/model_16.pth\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_y = test_model(test_x.to(device)).argmax(dim=1)\n",
        "print(test_y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kBkR-5nURJ_J",
        "outputId": "d0400aca-0d81-4a01-c5fa-f9cb46907313"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([100])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u3X_XnjVRJ-d",
        "outputId": "04d9e358-0c98-4d30-f62a-0dc499800a44"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([14, 14, 14, 14, 14, 14,  7,  7, 10,  7, 14, 14,  9, 17,  7, 14, 14,  9,\n",
            "        17,  9,  0,  6,  0, 14, 14,  7,  9,  9, 14,  1,  9,  1, 17,  7,  7, 10,\n",
            "         0,  0,  9,  7, 14,  9,  7,  9, 14,  7,  9, 14, 14, 14,  9,  7,  7,  4,\n",
            "         9,  2,  2, 14,  7,  7,  7, 17,  9,  0, 14, 14,  0, 14, 14,  7,  9,  0,\n",
            "         7, 14,  1,  7,  9, 14,  1, 14,  9,  0, 14,  0,  0,  0, 14,  7,  7, 17,\n",
            "        17, 14,  7,  7,  7, 14,  7, 14,  7, 10], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "submission = ['id,pred\\n']\n",
        "\n",
        "f2 = './lab1-2_data/submission_example.csv'"
      ],
      "metadata": {
        "id": "qRG4yb6pRJ6J"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(f2, 'rb') as f:\n",
        "    file = f.read().decode('utf-8')\n",
        "    content = file.split('\\n')[:-1] # 101 (column name included)\n",
        "\n",
        "    for idx, line in enumerate(content):\n",
        "        if idx == 0:\n",
        "            continue\n",
        "        tmp1 = line.split(',')\n",
        "        result = dict_category[test_y[idx-1].item()]\n",
        "        tmp2 = tmp1[0] + ',' + str(result) + '\\n'\n",
        "        submission.append(tmp2)"
      ],
      "metadata": {
        "id": "_9e8SbxfRnkM"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(submission)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vDS7Iav4RngU",
        "outputId": "db6953c9-d7ff-4ddb-fd35-79459655a9ce"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['id,pred\\n', 'S001,D20\\n', 'S002,D20\\n', 'S003,D20\\n', 'S004,D20\\n', 'S005,D20\\n', 'S006,D20\\n', 'S007,D12\\n', 'S008,D12\\n', 'S009,D16\\n', 'S010,D12\\n', 'S011,D20\\n', 'S012,D20\\n', 'S013,D15\\n', 'S014,D28\\n', 'S015,D12\\n', 'S016,D20\\n', 'S017,D20\\n', 'S018,D15\\n', 'S019,D28\\n', 'S020,D15\\n', 'S021,D1\\n', 'S022,D11\\n', 'S023,D1\\n', 'S024,D20\\n', 'S025,D20\\n', 'S026,D12\\n', 'S027,D15\\n', 'S028,D15\\n', 'S029,D20\\n', 'S030,D3\\n', 'S031,D15\\n', 'S032,D3\\n', 'S033,D28\\n', 'S034,D12\\n', 'S035,D12\\n', 'S036,D16\\n', 'S037,D1\\n', 'S038,D1\\n', 'S039,D15\\n', 'S040,D12\\n', 'S041,D20\\n', 'S042,D15\\n', 'S043,D12\\n', 'S044,D15\\n', 'S045,D20\\n', 'S046,D12\\n', 'S047,D15\\n', 'S048,D20\\n', 'S049,D20\\n', 'S050,D20\\n', 'S051,D15\\n', 'S052,D12\\n', 'S053,D12\\n', 'S054,D6\\n', 'S055,D15\\n', 'S056,D4\\n', 'S057,D4\\n', 'S058,D20\\n', 'S059,D12\\n', 'S060,D12\\n', 'S061,D12\\n', 'S062,D28\\n', 'S063,D15\\n', 'S064,D1\\n', 'S065,D20\\n', 'S066,D20\\n', 'S067,D1\\n', 'S068,D20\\n', 'S069,D20\\n', 'S070,D12\\n', 'S071,D15\\n', 'S072,D1\\n', 'S073,D12\\n', 'S074,D20\\n', 'S075,D3\\n', 'S076,D12\\n', 'S077,D15\\n', 'S078,D20\\n', 'S079,D3\\n', 'S080,D20\\n', 'S081,D15\\n', 'S082,D1\\n', 'S083,D20\\n', 'S084,D1\\n', 'S085,D1\\n', 'S086,D1\\n', 'S087,D20\\n', 'S088,D12\\n', 'S089,D12\\n', 'S090,D28\\n', 'S091,D28\\n', 'S092,D20\\n', 'S093,D12\\n', 'S094,D12\\n', 'S095,D12\\n', 'S096,D20\\n', 'S097,D12\\n', 'S098,D20\\n', 'S099,D12\\n', 'S100,D16\\n']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(f'./lab1-2_submissions/lab1-2_submission{exp_num}.csv', 'w') as f:\n",
        "    f.write(''.join(submission))"
      ],
      "metadata": {
        "id": "9axEFzCPRnb8"
      },
      "execution_count": 60,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "colab": {
      "name": "20214047_Jimin_Sohn_NLP_Lab1-2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}